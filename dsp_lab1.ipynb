{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNaCiW6MDKmn8GLrK+ufKK4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranee31/Knowledge-Alignment-Module/blob/main/dsp_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQDPyEDvQYWb",
        "outputId": "438e1c22-2cda-40a6-ed08-920f64da16f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the target string: mango\n",
            "Error fetching Google Search results: 'NoneType' object has no attribute 'text'. Retrying in 5 seconds...\n",
            "Error fetching Google Search results: 'NoneType' object has no attribute 'text'. Retrying in 5 seconds...\n",
            "Failed to fetch Google Search results after 3 attempts.\n",
            "No Google Search results found. Using Wikipedia summary only.\n",
            "Most relevant source: Wikipedia\n",
            "\n",
            "Relevant Knowledge:\n",
            "Manga (漫画, IPA: [maŋga] ) are comics or graphic novels originating from Japan. Most manga conform to a style developed in Japan in the late 19th century, and the form has a long history in earlier Japanese art. The term manga is used in Japan to refer to both comics and cartooning. Outside of Japan, the word is typically used to refer to comics originally published in Japan.\n",
            "In Japan, people of all ages and walks of life read manga. The medium includes works in a broad range of genres: action, adventure, business and commerce, comedy, detective, drama, historical, horror, mystery, romance, science fiction and fantasy, erotica (hentai and ecchi), sports and games, and suspense, among others. Many manga are translated into other languages.\n",
            "Since the 1950s, manga has become an increasingly major part of the Japanese publishing industry. By 1995, the manga market in Japan was valued at ¥586.4 billion ($6–7 billion), with annual sales of 1.9 billion manga books and manga magazines (also known as manga anthologies) in Japan (equivalent to 15 issues per person). In 2020 Japan's manga market value hit a new record of ¥612.6 billion due to the fast growth of digital manga sales as well as increase of print sales. In 2022 Japan's manga market hit yet another record value of ¥675.9 billion. Manga have also gained a significant worldwide readership. Beginning with the late 2010s manga started massively outselling American comics.\n",
            "As of 2021, the top four comics publishers in the world are manga publishers Shueisha, Kodansha, Kadokawa, and Shogakukan. In 2020 the North American manga market was valued at almost $250 million. According to NPD BookScan manga made up 76% of overall comics and graphic novel sales in the US in 2021. The fast growth of the North American manga market is attributed to manga's wide availability on digital reading apps, book retailer chains such as Barnes & Noble and online retailers such as Amazon as well as the increased streaming of anime. Manga represented 38% of the French comics market in 2005. This is equivalent to approximately three times that of the United States and was valued at about €460 million ($640 million). In Europe and the Middle East, the market was valued at $250 million in 2012. In April 2023, the Japan Business Federation laid out a proposal aiming to spur the economic growth of Japan by further promoting the contents industry abroad, primarily anime, manga and video games, for measures to invite industry experts from abroad to come to Japan to work, and to link with the tourism sector to help foreign fans of manga and anime visit sites across the country associated with particular manga stories. The federation seeks to quadruple the sales of Japanese content in overseas markets within the upcoming 10 years.\n",
            "Manga stories are typically printed in black-and-white—due to time constraints, artistic reasons (as coloring could lessen the impact of the artwork) and to keep printing costs low—although some full-color manga exist (e.g., Colorful). In Japan, manga are usually serialized in large manga magazines, often containing many stories, each presented in a single episode to be continued in the next issue. A single manga story is almost always longer than a single issue from a Western comic. Collected chapters are usually republished in tankōbon volumes, frequently but not exclusively paperback books. A manga artist (mangaka in Japanese) typically works with a few assistants in a small studio and is associated with a creative editor from a commercial publishing company. If a manga series is popular enough, it may be animated after or during its run. Sometimes, manga are based on previous live-action or animated films.\n",
            "Manga-influenced comics, among original works, exist in other parts of the world, particularly in those places that speak Chinese (\"manhua\"), Korean (\"manhwa\"), English (\"OEL manga\"), and French (\"manfra\"), as well as in the nation of Algeria (\"DZ-manga\").\n"
          ]
        }
      ],
      "source": [
        "import wikipedia\n",
        "import requests\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def fetch_wikipedia_knowledge(target_string):\n",
        "    try:\n",
        "        summary = wikipedia.summary(target_string)\n",
        "    except wikipedia.exceptions.PageError:\n",
        "        summary = \"No Wikipedia summary found.\"\n",
        "    except Exception as e:  # Handle generic exceptions\n",
        "        summary = f\"Error fetching Wikipedia summary: {e}\"\n",
        "    return summary\n",
        "\n",
        "def fetch_google_search_results(target_string, max_retries=3, delay=5):\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            url = f\"https://www.google.com/search?q={target_string}\"\n",
        "            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'}\n",
        "            response = requests.get(url, headers=headers)\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Check if results are found\n",
        "            results = soup.find_all('div', class_='g')\n",
        "            if not results:\n",
        "                return []  # Return an empty list if no results\n",
        "\n",
        "            snippets = [result.find('div', class_='s3').text for result in results]\n",
        "            return snippets\n",
        "        except Exception as e:  # Handle generic exceptions\n",
        "            if attempt < max_retries - 1:\n",
        "                print(f\"Error fetching Google Search results: {e}. Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "            else:\n",
        "                print(f\"Failed to fetch Google Search results after {max_retries} attempts.\")\n",
        "                return []\n",
        "\n",
        "def calculate_similarity(text1, text2):\n",
        "    try:\n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        embeddings = model.encode([text1, text2])\n",
        "        similarity_score = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
        "        return similarity_score\n",
        "    except Exception as e:  # Handle generic exceptions\n",
        "        print(f\"Error calculating similarity: {e}\")\n",
        "        return 0.0  # Return 0 as a default similarity score\n",
        "\n",
        "def semantic_similarity_verification(target_string, wikipedia_summary, google_snippets):\n",
        "    wiki_similarity = calculate_similarity(target_string, wikipedia_summary)\n",
        "\n",
        "    # Handle empty google_snippets list\n",
        "    if not google_snippets:\n",
        "        print(\"No Google Search results found. Using Wikipedia summary only.\")\n",
        "        return \"Wikipedia\", wikipedia_summary\n",
        "\n",
        "    google_similarities = [calculate_similarity(target_string, snippet) for snippet in google_snippets]\n",
        "    max_google_similarity = max(google_similarities)\n",
        "\n",
        "    if wiki_similarity > max_google_similarity:\n",
        "        return \"Wikipedia\", wikipedia_summary\n",
        "    else:\n",
        "        return \"Google Snippets\", max(google_similarities, key=lambda x: x[1])[0]\n",
        "\n",
        "def main():\n",
        "    target_string = input(\"Enter the target string: \")\n",
        "\n",
        "    wikipedia_summary = fetch_wikipedia_knowledge(target_string)\n",
        "    google_snippets = fetch_google_search_results(target_string)\n",
        "\n",
        "    most_relevant_source, relevant_text = semantic_similarity_verification(target_string, wikipedia_summary, google_snippets)\n",
        "\n",
        "    print(f\"Most relevant source: {most_relevant_source}\")\n",
        "    print(\"\\nRelevant Knowledge:\")\n",
        "    print(relevant_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia requests beautifulsoup4 sentence-transformers scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0MLc955QcVr",
        "outputId": "53881f42-e5ea-4334-d75b-f08cf6e2a10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=9bbcab6a7b1087eff06e94586101a5f7292b2bb8578182c2f11e9f846a301a5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    }
  ]
}